{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2cced3",
   "metadata": {},
   "source": [
    "# Underfitting and Overfitting\n",
    "Fine-tune your model for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5be4c8",
   "metadata": {},
   "source": [
    "**overfitting**, where a model matches the training data almost perfectly, but does poorly in validation and other new data. \n",
    "\n",
    "On the flip side, if we make our tree very shallow, it doesn't divide up the houses into very distinct groups.\n",
    "\n",
    "When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called **underfitting**.\n",
    "\n",
    "Since we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting. Visually, we want the low point of the (red) validation curve in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad475ed0",
   "metadata": {},
   "source": [
    "![alt text](http://i.imgur.com/AXSEOfI.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c014a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6a96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Code Runs At This Point\n",
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "melbourne_file_path = '01_input/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c685131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  347380.33833344496\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  258171.21202406782\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  243495.96361790417\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  254983.64299548094\n"
     ]
    }
   ],
   "source": [
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(f\"Max leaf nodes: {max_leaf_nodes}  \\t\\t Mean Absolute Error:  {my_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be4e4d",
   "metadata": {},
   "source": [
    "Of the options listed, 500 is the optimal number of leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f1201",
   "metadata": {},
   "source": [
    "Here's the takeaway: Models can suffer from either:\n",
    "\n",
    "* Overfitting: capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or\n",
    "* Underfitting: failing to capture relevant patterns, again leading to less accurate predictions.\n",
    "\n",
    "<br>\n",
    "\n",
    "We use validation data, which isn't used in model training, to measure a candidate model's accuracy. This lets us try many candidate models and keep the best one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
